# ------------------------------------------------------
# THIS FILE WAS AUTOMATICALLY GENERATED (DO NOT MODIFY)
# ------------------------------------------------------

type Choice {
  finish_reason: String!
  index: Float!
  logprobs: Float
  text: String!
}

type Completion {
  choices: [Choice!]!
  created: Float!
  id: String!
  model: String!
  object: String!
  usage: Usage!
}

input CreateCompletionInput {
  """
  Generates best_of completions server-side and returns the "best" (the one with the highest log probability per token).
  """
  best_of: Float

  """Echo back the prompt in addition to the completion."""
  echo: Boolean

  """
  Number between -2.0 and 2.0. Positive values penalize new tokens based on their existing frequency in the text so far.
  """
  frequency_penalty: Float

  """Modify the likelihood of specified tokens appearing in the completion."""
  logit_bias: [String!]

  """Include the log probabilities on the logprobs most likely tokens."""
  logprobs: Float

  """The maximum number of tokens to generate in the completion."""
  max_tokens: Float

  """ID of the model to use."""
  model: String!

  """How many completions to generate for each prompt."""
  n: Float

  """
  Number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the text so far.
  """
  presence_penalty: Float

  """The prompt(s) to generate completions for."""
  prompt: String!

  """Up to 4 sequences where the API will stop generating further tokens."""
  stop: [String!]

  """Whether to stream back partial progress."""
  stream: Boolean

  """The suffix that comes after a completion of inserted text."""
  suffix: String

  """What sampling temperature to use, between 0 and 2."""
  temperature: Float

  """An alternative to sampling with temperature, called nucleus sampling."""
  top_p: Float

  """A unique identifier representing your end-user."""
  user: String
}

type Model {
  """The ID of the model."""
  id: String!

  """The type of the object."""
  object: String!

  """The owner of the model."""
  owned_by: String!
  permission: [Permission!]
}

type ModelsResponse {
  data: [Model!]!
  object: String!
}

type Mutation {
  """Creates a completion for the provided prompt and parameters."""
  createCompletion(input: CreateCompletionInput!): Completion!
}

type Permission {
  allow_create_engine: Boolean!
  allow_fine_tuning: Boolean!
  allow_logprobs: Boolean!
  allow_sampling: Boolean!
  allow_search_indices: Boolean!
  allow_view: Boolean!
  created: Float!
  group: String
  id: String!
  is_blocking: Boolean!
  object: String!
  organization: String!
}

type Query {
  """Retrieves a model instance."""
  model(
    """The ID of the model to retrieve."""
    id: String!
  ): Model!

  """Lists the currently available models."""
  models: ModelsResponse!
}

type Usage {
  completion_tokens: Float!
  prompt_tokens: Float!
  total_tokens: Float!
}